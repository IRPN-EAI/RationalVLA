<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>RationalVLA</title>
<!--   <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">RationalVLA: A Dual-system Vision-Language-Action Model for Defective Instructions</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <div class="is-size-5 publication-authors">
                    <a href="https://fake.link/wenxuan-song">Wenxuan Song</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/jiayi-chen">Jiayi Chen</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/wenxue-li">Wenxue Li</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/xu-he">Xu He</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/han-zhao">Han Zhao</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/xu-he">Can Cui</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/pengxiang-ding">Pengxiang Ding</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/shiyan-su">Shiyan Su</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/feilong-tang">Feilong Tang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/donglin-wang">Donglin Wang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/xuelian-cheng">Xuelian Cheng</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/zongyuan-ge">Zongyuan Ge</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/haoang-li">Zhe Liu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/haoang-li">Hesheng Wang</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/haoang-li">Yun-hui Liu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <a href="https://fake.link/haoang-li">Haoang Li</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<!--                   Wenxuan Song, Jiayi Chen, Wenxue Li, Xu He, Han Zhao, Can Cui, Pengxiang Ding, Shiyan Su, Feilong Tang, Donglin Wang, Xuelian Cheng, Zongyuan Ge, Xinhu Zheng, Zhe Liu, Hesheng Wang, Yun-hui Liu, Haoang Li -->
                    <!-- <br /><sup>*</sup>Indicates co-first author<br /> -->
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                      <span class="author-block">The Hong Kong University of Science and Technology (Guangzhou)</span><br>
                      <span class="author-block">Shanghai Jiao Tong University</span><br> 
                      <span class="eql-cntrb"><small><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2506.10826" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                   
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2506.10826" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--    <iframe 
            width="920" 
            height="540"
            src="https://www.youtube.com/embed/FsDTfXPLufo?autoplay=0&enablejsapi=1"
            frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
            allowfullscreen>
          </iframe>
         
        <h2 class="subtitle has-text-centered">
          A Dual-system Vision-Language-Action Model for Rational Manipulation<section class="hero is-small is-light"> </h2> -->
  <!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">A Dual-system Vision-Language-Action Model for Rational Manipulation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/FsDTfXPLufo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
       

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            A fundamental requirement for real-world robotic deployment is the ability to understand and respond to natural language instructions. Existing language-conditioned manipulation tasks typically assume that instructions are perfectly aligned with the environment. This assumption limits robustness and generalization in realistic scenarios where instructions may be ambiguous, irrelevant, or infeasible. To address this problem, we introduce RAtional MAnipulation (RAMA), a new benchmark that challenges models with both unseen executable instructions and defective ones that should be rejected. In RAMA, we construct a dataset with over 14,000 samples, including diverse defective instructions spanning six dimensions: visual, physical, semantic, motion, safety, and out-of-context. We further propose the Rational Vision-Language-Action model (RationalVLA). It is a dual system for robotic arms that integrates the high-level vision-language model with the low-level manipulation policy by introducing learnable latent space embeddings. This design enables RationalVLA to reason over instructions, reject infeasible commands, and execute manipulation effectively. Experiments demonstrate that RationalVLA outperforms state-of-the-art baselines on RAMA by a 14.5% higher success rate and 0.94 average task length, while maintaining competitive performance on standard manipulation tasks. Real-world trials further validate its effectiveness and robustness in practical applications.          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

    <!--  teaser video -->
              <!-- Youtube embed code here -->
<!--               <iframe src="https://www.youtu.be/embed/KCNbmGXn7Ms" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> 
          src="https://www.youtube.com/embed/KCNbmGXn7Ms?autoplay=0&enablejsapi=1"    vpwS2LkHZ4A-->
         
<!--     </div>
  </div>
</section> -->
<!-- End teaser video -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{song2025rational,
          author    = {Song, Wenxuan and Chen, Jiayi and Li, Wenxue and He, Xu and Zhao, Han and Ding, Pengxiang and Wang, Donglin and Su, Shiyan and Tang, Feilong and Cheng, Xuelian and Ge, Zongyuan and Zheng, Xinhu and Liu, Zhe and Wang, Hesheng and Liu, Yun-hui and Li, Haoang},
          title     = {RationalVLA: A Rational Vision-Language-Action Model with Dual System},
          journal   = {arXiv preprint arXiv:2506.10826},
          year      = {2025},
        }
</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!--   <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
